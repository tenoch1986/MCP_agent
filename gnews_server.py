#!/usr/bin/env python3
"""
GNews API MCP æœåŠ¡å™¨ - é€šè¿‡ GNews API æŸ¥è¯¢æ–°é—»

åŠŸèƒ½ï¼š
- æä¾›æ–°é—»æœç´¢å·¥å…·
- æ”¯æŒå¤šç§æœç´¢å‚æ•°
- æ”¯æŒ SSE ä¼ è¾“æ¨¡å¼
"""

import json
import urllib.request
from urllib.parse import quote
from typing import Optional
from mcp.server import FastMCP

# åˆ›å»º MCP æœåŠ¡å™¨å®ä¾‹
mcp = FastMCP("gnews_server", port=8002)

# GNews API é…ç½®
GNEWS_API_KEY = "52a1e33ade91f472baca36ff22e115be"
BASE_URL = "https://gnews.io/api/v4/search"

def build_gnews_url(
    query: str,
    lang: str = "zh",
    country: str = "cn",
    max_results: int = 10,
    sort_by: str = "publishedAt"
) -> str:
    """æ„å»º GNews API URL"""
    # URL ç¼–ç æŸ¥è¯¢å‚æ•°
    encoded_query = quote(query)
    
    url = f"{BASE_URL}?q={encoded_query}&lang={lang}&country={country}&max={max_results}&sortby={sort_by}&apikey={GNEWS_API_KEY}"
    return url

def fetch_news_from_gnews(url: str) -> dict:
    """ä» GNews API è·å–æ–°é—»æ•°æ®"""
    try:
        with urllib.request.urlopen(url) as response:
            data = json.loads(response.read().decode("utf-8"))
            return data
    except Exception as e:
        return {"error": f"è·å–æ–°é—»å¤±è´¥: {str(e)}"}

@mcp.tool()
async def search_news(
    query: str,
    lang: str = "zh",
    country: str = "cn",
    max_results: int = 10,
    sort_by: str = "publishedAt"
) -> str:
    """æœç´¢æ–°é—»æ–‡ç« 
    
    Args:
        query: æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒé€»è¾‘è¿ç®—ç¬¦ AND, OR, NOTï¼‰
        lang: è¯­è¨€ä»£ç  (zh=ä¸­æ–‡, en=è‹±æ–‡ç­‰)
        country: å›½å®¶ä»£ç  (cn=ä¸­å›½, us=ç¾å›½ç­‰)
        max_results: è¿”å›ç»“æœæ•°é‡ (1-100)
        sort_by: æ’åºæ–¹å¼ (publishedAt=å‘å¸ƒæ—¶é—´, relevance=ç›¸å…³æ€§)
    """
    if not query:
        return "é”™è¯¯ï¼šè¯·æä¾›æœç´¢å…³é”®è¯"
    
    # éªŒè¯å‚æ•°
    if max_results < 1 or max_results > 100:
        return "é”™è¯¯ï¼šmax_results å¿…é¡»åœ¨ 1-100 ä¹‹é—´"
    
    if sort_by not in ["publishedAt", "relevance"]:
        return "é”™è¯¯ï¼šsort_by å¿…é¡»æ˜¯ 'publishedAt' æˆ– 'relevance'"
    
    # æ„å»º API URL
    url = build_gnews_url(query, lang, country, max_results, sort_by)
    
    # è·å–æ–°é—»æ•°æ®
    data = fetch_news_from_gnews(url)
    
    if "error" in data:
        return data["error"]
    
    articles = data.get("articles", [])
    total_articles = data.get("totalArticles", 0)
    
    if not articles:
        return f"æ²¡æœ‰æ‰¾åˆ°å…³äº '{query}' çš„æ–°é—»"
    
    # æ ¼å¼åŒ–ç»“æœ
    result = f"ğŸ“° å…³äº '{query}' çš„æ–°é—»æœç´¢ç»“æœ ({total_articles} æ¡ç»“æœ)\n\n"
    
    for i, article in enumerate(articles[:max_results], 1):
        result += f"**{i}. {article.get('title', 'æ— æ ‡é¢˜')}**\n"
        result += f"   æè¿°: {article.get('description', 'æ— æè¿°')}\n"
        result += f"   æ¥æº: {article.get('source', {}).get('name', 'æœªçŸ¥')}\n"
        result += f"   å‘å¸ƒæ—¶é—´: {article.get('publishedAt', 'æœªçŸ¥')}\n"
        result += f"   é“¾æ¥: {article.get('url', 'æ— é“¾æ¥')}\n\n"
    
    return result

@mcp.tool()
async def get_top_headlines(
    category: str = "general",
    country: str = "cn",
    max_results: int = 10
) -> str:
    """è·å–å¤´æ¡æ–°é—»
    
    Args:
        category: æ–°é—»ç±»åˆ« (general, world, nation, business, technology, entertainment, sports, science, health)
        country: å›½å®¶ä»£ç 
        max_results: è¿”å›ç»“æœæ•°é‡
    """
    # ä½¿ç”¨ GNews çš„æœç´¢åŠŸèƒ½æ¨¡æ‹Ÿå¤´æ¡æ–°é—»
    query = "æœ€æ–° æ–°é—»"
    
    url = build_gnews_url(query, "zh", country, max_results, "publishedAt")
    data = fetch_news_from_gnews(url)
    
    if "error" in data:
        return data["error"]
    
    articles = data.get("articles", [])
    
    if not articles:
        return f"æ²¡æœ‰æ‰¾åˆ° {category} ç±»åˆ«çš„å¤´æ¡æ–°é—»"
    
    result = f"ğŸ“¢ {category.capitalize()} ç±»åˆ«å¤´æ¡æ–°é—»\n\n"
    
    for i, article in enumerate(articles[:max_results], 1):
        result += f"**{i}. {article.get('title', 'æ— æ ‡é¢˜')}**\n"
        result += f"   æè¿°: {article.get('description', 'æ— æè¿°')}\n"
        result += f"   æ¥æº: {article.get('source', {}).get('name', 'æœªçŸ¥')}\n"
        result += f"   å‘å¸ƒæ—¶é—´: {article.get('publishedAt', 'æœªçŸ¥')}\n\n"
    
    return result

@mcp.tool()
async def search_news_by_topic(
    topic: str,
    lang: str = "zh",
    max_results: int = 10
) -> str:
    """æŒ‰ä¸»é¢˜æœç´¢æ–°é—»
    
    Args:
        topic: æ–°é—»ä¸»é¢˜ (å¦‚: ç§‘æŠ€, ä½“è‚², è´¢ç», å¨±ä¹ç­‰)
        lang: è¯­è¨€ä»£ç 
        max_results: è¿”å›ç»“æœæ•°é‡
    """
    # ä¸­æ–‡ä¸»é¢˜æ˜ å°„åˆ°è‹±æ–‡å…³é”®è¯
    topic_mapping = {
        "ç§‘æŠ€": "technology",
        "ä½“è‚²": "sports", 
        "è´¢ç»": "finance",
        "å¨±ä¹": "entertainment",
        "å¥åº·": "health",
        "ç§‘å­¦": "science",
        "æ”¿æ²»": "politics",
        "æ•™è‚²": "education"
    }
    
    # å¦‚æœä¸»é¢˜åœ¨æ˜ å°„ä¸­ï¼Œä½¿ç”¨è‹±æ–‡å…³é”®è¯ï¼Œå¦åˆ™ä½¿ç”¨ä¸­æ–‡
    if topic in topic_mapping:
        query = topic_mapping[topic]
    else:
        query = topic
    
    url = build_gnews_url(query, lang, "cn", max_results, "publishedAt")
    data = fetch_news_from_gnews(url)
    
    if "error" in data:
        return data["error"]
    
    articles = data.get("articles", [])
    total_articles = data.get("totalArticles", 0)
    
    if not articles:
        return f"æ²¡æœ‰æ‰¾åˆ°å…³äº '{topic}' ä¸»é¢˜çš„æ–°é—»"
    
    result = f"ğŸ“° {topic} ä¸»é¢˜æ–°é—» ({total_articles} æ¡ç»“æœ)\n\n"
    
    for i, article in enumerate(articles[:max_results], 1):
        result += f"**{i}. {article.get('title', 'æ— æ ‡é¢˜')}**\n"
        result += f"   æè¿°: {article.get('description', 'æ— æè¿°')}\n"
        result += f"   æ¥æº: {article.get('source', {}).get('name', 'æœªçŸ¥')}\n"
        result += f"   å‘å¸ƒæ—¶é—´: {article.get('publishedAt', 'æœªçŸ¥')}\n\n"
    
    return result

# å…³é”®ï¼šä¸è¦åŠ å¤šä½™çš„ printï¼Œå¦åˆ™ç ´å JSON-RPC åè®®ï¼
if __name__ == "__main__":
    mcp.run(transport="sse")
